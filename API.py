# -*- coding: utf-8 -*-
"""Challenge

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M9u7wSJvte40s-i-mYjxL4_tUrHxHKDh
"""

# Import Regex, Sqlite, and Pandas
import re
import sqlite3
import pandas as pd

# Import library for Flask
from flask import Flask, jsonify
from flask import request
from flasgger import Swagger, LazyString, LazyJSONEncoder
from flasgger import swag_from

# Define Swagger UI description
app = Flask(__name__)
app.json_encoder = LazyJSONEncoder
swagger_template = dict(
info = {
    'title': LazyString(lambda: 'API Documentation for Tweet Data Cleansing'),
    'version': LazyString(lambda: '1.0.0'),
    'description': LazyString(lambda: 'Dokumentasi API untuk Tweet Data Cleansing'),
    },
    host = LazyString(lambda: request.host)
)
swagger_config = {
    "headers": [],
    "specs": [
        {
            "endpoint": 'docs',
            "route": '/docs.json',
        }
    ],
    "static_url_path": "/flasgger_static",
    "swagger_ui": True,
    "specs_route": "/docs/"
}
swagger = Swagger(app, template=swagger_template,             
                  config=swagger_config)

# Connect to database
conn = sqlite3.connect('data/database.db', check_same_thread=False)
conn.row_factory = sqlite3.Row
mycursor = conn.cursor()

# Define and execute query for create table "data" if not exist
# Table "Data" contains "text" coloumn and "text_clean" coloumn. The two columns have "varchar" data type
conn.execute('''CREATE TABLE IF NOT EXISTS data (text varchar(255), text_clean varchar(255));''')

# Define data cleaning function
def data_cleaning(text):
  text = re.sub('USER', '', text) #Remove USER
  text = re.sub('RT', '', text) #Remove RT
  text = re.sub('URL', '', text) #Remove URL
  text = re.sub(r'\\n+', '', text) #Remove \n
  text = re.sub(r'https\S+','', text) #Remove https
  text = re.sub(r'\\x[A-Za-z0-9./]+', '', text) #Remove \x96 etc
  text = re.sub('#[A-Za-z0-9./]+', '', text) #Remove hastag
  text = re.sub('  +', '', text) #Remove extra space
  return text.lower() #Lowercase text

def data_cleaning2(text):
  text = re.sub('[^0-9a-zA-Z]+', ' ', text) #Remove non alpha numeric
  return text

def preprocess(text):
    text = data_cleaning(text)
    text = data_cleaning2(text)
    return text

# Define function for processing csv file
def cleansing_file(input_file):
  column = input_file.iloc[:,0]
  print(column)

  for data in column:
    text_clean = preprocess(data)
    query_text = "insert into data(text,text_clean) values(?,?)"
    val = (data, text_clean)
    mycursor.execute(query_text, val)
    conn.commit()
    print(data)

# Define endpoint for text input via form
@swag_from("docs/text.yml", methods=['POST'])
@app.route('/text-processing', methods=['POST'])
def text_processing():

    # Get text file
    text = request.form.get('text')
    
    # Cleansing process
    text_clean = preprocess(text)

    # Define and execute query for insert original text and cleaned text to sqlite database
    conn.execute("INSERT INTO data (text, text_clean) VALUES ('" + text + "', '" + text_clean + "')")
    conn.commit()

    # Define API response
    json_response = {
        'status_code': 200,
        'description': "Teks yang sudah diproses",
        'data': text_clean,
    }
    response_data = jsonify(json_response)
    return response_data

# Define endpoint for text input via upload CSV file
@swag_from("docs/text_file.yml", methods=['POST'])
@app.route('/text-processing-file', methods=['POST'])
def input_csv():
  # Get CSV file
  file = request.files['file']
  # Read CSV file
  try:
    data_csv = pd.read_csv(file, encoding='iso-8859-1')
  except:
    data_csv = pd.read_csv(file, encoding='utf-8')
  # Cleansing process
  cleansing_file(data_csv)
  # Define API response
  query_text = "select * from data"
  select_data = mycursor.execute(query_text)
  conn.commit
  data=[
      dict(text_clean=row[1])
  for row in select_data.fetchall()
  ]

  return jsonify(data)  

if __name__ == '__main__':
   app.run()